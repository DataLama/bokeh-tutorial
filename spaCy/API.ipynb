{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doc object owns the sequence of tokens and all their annotations.\n",
    "- Vocab object owns a set of look-up tables that make common information available across documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy + custom tokenizer... + basic tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from spacy.lang.ko import Korean, KoreanTokenizer\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "nlp = Korean()\n",
    "tokenizer = LTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14802192752119398744"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[13].tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ DET\n",
      "ê±´ì„± NOUN\n",
      "ì…ë‹ˆë‹¤ ADP\n",
      "ğŸ˜Š SYM\n",
      "ì ë‹¹ X\n",
      "í•œ X\n",
      "ìœ ë¶„ NOUN\n",
      "ë„ ADP\n",
      "ê°€ì§€ AUX\n",
      "ê³  X\n",
      "ìˆ AUX\n",
      "ëŠ” X\n",
      "ë° NOUN\n",
      "ê°€ë²¼ì›Œì„œ ADJ\n",
      "í™”ì¥ NOUN\n",
      "ì „ NOUN\n",
      "ì— ADP\n",
      "ë°”ë¥´ VERB\n",
      "ê¸° X\n",
      "ë„ ADP\n",
      "ì¢‹ ADJ\n",
      "ì•„ìš” X\n",
      "! PUNCT\n",
      "ë°¤ NOUN\n",
      "ì— ADP\n",
      "ë°”ë¥´ VERB\n",
      "ë©´ X\n",
      "ì† NOUN\n",
      "ê¹Œì§€ ADP\n",
      "ìœ ìˆ˜ NOUN\n",
      "ë¶„ê° NOUN\n",
      "ì´ ADP\n",
      "ì°¨ì˜¤ë¥´ VERB\n",
      "ê³  X\n",
      "ì´‰ì´‰ X\n",
      "í•˜ X\n",
      "ê³  X\n",
      "ì „ PRON\n",
      "ì•„ì£¼ ADV\n",
      "ì¢‹ ADJ\n",
      "ì•„ìš” X\n",
      "ì•… X\n",
      "ê±´ì„± NOUN\n",
      "ì¸ ADP\n",
      "ë¶„ NOUN\n",
      "ë“¤ X\n",
      "ì€ ADP\n",
      "í¬ë¦¼ NOUN\n",
      "í•˜ë‚˜ NUM\n",
      "ë” ADV\n",
      "ë°œë¼ì•¼ VERB\n",
      "í•  AUX\n",
      "ë“¯ NOUN\n",
      "ì‹¶ AUX\n",
      "ì–´ìš” X\n",
      "! PUNCT\n",
      "ì „ PRON\n",
      "ì—„ì²­ë‚œ ADJ\n",
      "ê±´ì„± NOUN\n",
      "ì€ ADP\n",
      "ì•„ë‹ˆ ADJ\n",
      "ë¼ì„œ X\n",
      "í”¼ê³¤ NOUN\n",
      "í•  X\n",
      "ë•Œ NOUN\n",
      "ëŠ” ADP\n",
      "ê·¸ëƒ¥ ADV\n",
      "ë¡œì…˜ NOUN\n",
      "ë§Œ ADP\n",
      "ë°”ë¥´ VERB\n",
      "ê¸° X\n",
      "ë„ ADP\n",
      "í•´ìš” VERB\n",
      "! PUNCT\n",
      "ì•„ì¹¨ NOUN\n",
      "ì— ADP\n",
      "ëŠ” ADP\n",
      "ìŠ¤í‚¨ NOUN\n",
      "ë°”ë¥´ VERB\n",
      "ê³  X\n",
      "ë¡œì…˜ NOUN\n",
      "ë§Œ ADP\n",
      "ë°”ë¥´ ADJ\n",
      "ê³  X\n",
      "ì„ í¬ë¦¼ NOUN\n",
      "ë°”ë¥´ VERB\n",
      "ê³  X\n",
      "í™”ì¥ NOUN\n",
      "í•´ìš” X\n",
      "! PUNCT\n",
      "ê·¸ë˜ë„ CONJ\n",
      "ì ë‹¹íˆ ADV\n",
      "ì´‰ì´‰ X\n",
      "í•˜ X\n",
      "ê³  X\n",
      "ì¢‹ ADJ\n",
      "ì•„ìš” X\n",
      "í™”ì¥ NOUN\n",
      "ì „ NOUN\n",
      "ê¸°ì´ˆ NOUN\n",
      "ë¥¼ ADP\n",
      "ì—¬ëŸ¬ DET\n",
      "ê°œ NOUN\n",
      "í•´ì„œ VERB\n",
      "í”¼ë¶€ NOUN\n",
      "ë‹µë‹µ X\n",
      "í•œ X\n",
      "ê±° NOUN\n",
      "ì‹« ADJ\n",
      "ì€ë° X\n",
      "ì´ DET\n",
      "ë¡œì…˜ NOUN\n",
      "ì€ ADP\n",
      "ì•ˆ ADV\n",
      "ê·¸ë˜ì„œ VERB\n",
      "ì¢‹ ADJ\n",
      "ì•„ìš” X\n",
      "ì´ë¯¸ ADV\n",
      "í•œ DET\n",
      "í†µ NOUN\n",
      "ë¹„ì›Œì„œ VERB\n",
      "í•œ DET\n",
      "í†µ NOUN\n",
      "ë” ADV\n",
      "ì‚´ VERB\n",
      "ìƒê° NOUN\n",
      "ì…ë‹ˆë‹¤ ADP\n",
      "! PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoyTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        words = tokenizer.tokenize(text)\n",
    "        # All tokens 'own' a subsequent space character in this tokenizer\n",
    "        spaces = [True] * len(words)\n",
    "        return Doc(self.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer = SoyTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"ì „ ê±´ì„±ì…ë‹ˆë‹¤ğŸ˜Š\n",
    "ì ë‹¹í•œ ìœ ë¶„ë„ ê°€ì§€ê³  ìˆëŠ”ë° ê°€ë²¼ì›Œì„œ í™”ì¥ ì „ì— ë°”ë¥´ê¸°ë„ ì¢‹ì•„ìš”!\n",
    "ë°¤ì— ë°”ë¥´ë©´ ì†ê¹Œì§€ ìœ ìˆ˜ë¶„ê°ì´ ì°¨ì˜¤ë¥´ê³  ì´‰ì´‰í•˜ê³  ì „ ì•„ì£¼ ì¢‹ì•„ìš” ì•…ê±´ì„±ì¸ ë¶„ë“¤ì€ í¬ë¦¼ í•˜ë‚˜ ë” ë°œë¼ì•¼ í•  ë“¯ ì‹¶ì–´ìš”! ì „ ì—„ì²­ë‚œ ê±´ì„±ì€ ì•„ë‹ˆë¼ì„œ í”¼ê³¤í•  ë•ŒëŠ” ê·¸ëƒ¥ ë¡œì…˜ë§Œ ë°”ë¥´ê¸°ë„ í•´ìš”!\n",
    "ì•„ì¹¨ì—ëŠ” ìŠ¤í‚¨ ë°”ë¥´ê³  ë¡œì…˜ë§Œ ë°”ë¥´ê³  ì„ í¬ë¦¼ ë°”ë¥´ê³  í™”ì¥í•´ìš”! ê·¸ë˜ë„ ì ë‹¹íˆ ì´‰ì´‰í•˜ê³  ì¢‹ì•„ìš” í™”ì¥ ì „ ê¸°ì´ˆë¥¼ ì—¬ëŸ¬ê°œ í•´ì„œ í”¼ë¶€ ë‹µë‹µí•œ ê±° ì‹«ì€ë° ì´ ë¡œì…˜ì€ ì•ˆ ê·¸ë˜ì„œ ì¢‹ì•„ìš” ì´ë¯¸ í•œ í†µ ë¹„ì›Œì„œ í•œ í†µ ë” ì‚´ ìƒê°ì…ë‹ˆë‹¤!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ \n",
      "ê±´ì„±ì…ë‹ˆë‹¤ğŸ˜Š \n",
      "ì ë‹¹í•œ \n",
      "ìœ ë¶„ë„ \n",
      "ê°€ì§€ê³  \n",
      "ìˆëŠ”ë° \n",
      "ê°€ë²¼ì›Œì„œ \n",
      "í™”ì¥ \n",
      "ì „ì— \n",
      "ë°”ë¥´ê¸°ë„ \n",
      "ì¢‹ì•„ìš”! \n",
      "ë°¤ì— \n",
      "ë°”ë¥´ë©´ \n",
      "ì†ê¹Œì§€ \n",
      "ìœ ìˆ˜ë¶„ê°ì´ \n",
      "ì°¨ì˜¤ë¥´ê³  \n",
      "ì´‰ì´‰í•˜ê³  \n",
      "ì „ \n",
      "ì•„ì£¼ \n",
      "ì¢‹ì•„ìš” \n",
      "ì•…ê±´ì„±ì¸ \n",
      "ë¶„ë“¤ì€ \n",
      "í¬ë¦¼ \n",
      "í•˜ë‚˜ \n",
      "ë” \n",
      "ë°œë¼ì•¼ \n",
      "í•  \n",
      "ë“¯ \n",
      "ì‹¶ì–´ìš”! \n",
      "ì „ \n",
      "ì—„ì²­ë‚œ \n",
      "ê±´ì„±ì€ \n",
      "ì•„ë‹ˆë¼ì„œ \n",
      "í”¼ê³¤í•  \n",
      "ë•ŒëŠ” \n",
      "ê·¸ëƒ¥ \n",
      "ë¡œì…˜ë§Œ \n",
      "ë°”ë¥´ê¸°ë„ \n",
      "í•´ìš”! \n",
      "ì•„ì¹¨ì—ëŠ” \n",
      "ìŠ¤í‚¨ \n",
      "ë°”ë¥´ê³  \n",
      "ë¡œì…˜ë§Œ \n",
      "ë°”ë¥´ê³  \n",
      "ì„ í¬ë¦¼ \n",
      "ë°”ë¥´ê³  \n",
      "í™”ì¥í•´ìš”! \n",
      "ê·¸ë˜ë„ \n",
      "ì ë‹¹íˆ \n",
      "ì´‰ì´‰í•˜ê³  \n",
      "ì¢‹ì•„ìš” \n",
      "í™”ì¥ \n",
      "ì „ \n",
      "ê¸°ì´ˆë¥¼ \n",
      "ì—¬ëŸ¬ê°œ \n",
      "í•´ì„œ \n",
      "í”¼ë¶€ \n",
      "ë‹µë‹µí•œ \n",
      "ê±° \n",
      "ì‹«ì€ë° \n",
      "ì´ \n",
      "ë¡œì…˜ì€ \n",
      "ì•ˆ \n",
      "ê·¸ë˜ì„œ \n",
      "ì¢‹ì•„ìš” \n",
      "ì´ë¯¸ \n",
      "í•œ \n",
      "í†µ \n",
      "ë¹„ì›Œì„œ \n",
      "í•œ \n",
      "í†µ \n",
      "ë” \n",
      "ì‚´ \n",
      "ìƒê°ì…ë‹ˆë‹¤! \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14630057439605637705"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.strings[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë°”ë¥´ë©´'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[12]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[12].is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[doc[1].text].is_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ê°€'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6].prefix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë²¼ì›Œì„œ'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6].suffix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_extension',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'string',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'check_flag',\n",
       " 'cluster',\n",
       " 'flags',\n",
       " 'from_bytes',\n",
       " 'has_vector',\n",
       " 'is_alpha',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'sentiment',\n",
       " 'set_attrs',\n",
       " 'set_flag',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'text',\n",
       " 'to_bytes',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nlp.vocab[doc[0].text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì „', 'ê±´ì„±ì…ë‹ˆë‹¤ğŸ˜Š', 'ì ë‹¹í•œ', 'ìœ ë¶„ë„', 'ê°€ì§€ê³ ', 'ìˆëŠ”ë°', 'ê°€ë²¼ì›Œì„œ', 'í™”ì¥', 'ì „ì—', 'ë°”ë¥´ê¸°ë„', 'ì¢‹ì•„ìš”!', 'ë°¤ì—', 'ë°”ë¥´ë©´', 'ì†ê¹Œì§€', 'ìœ ìˆ˜ë¶„ê°ì´', 'ì°¨ì˜¤ë¥´ê³ ', 'ì´‰ì´‰í•˜ê³ ', 'ì „', 'ì•„ì£¼', 'ì¢‹ì•„ìš”', 'ì•…ê±´ì„±ì¸', 'ë¶„ë“¤ì€', 'í¬ë¦¼', 'í•˜ë‚˜', 'ë”', 'ë°œë¼ì•¼', 'í• ', 'ë“¯', 'ì‹¶ì–´ìš”!', 'ì „', 'ì—„ì²­ë‚œ', 'ê±´ì„±ì€', 'ì•„ë‹ˆë¼ì„œ', 'í”¼ê³¤í• ', 'ë•ŒëŠ”', 'ê·¸ëƒ¥', 'ë¡œì…˜ë§Œ', 'ë°”ë¥´ê¸°ë„', 'í•´ìš”!', 'ì•„ì¹¨ì—ëŠ”', 'ìŠ¤í‚¨', 'ë°”ë¥´ê³ ', 'ë¡œì…˜ë§Œ', 'ë°”ë¥´ê³ ', 'ì„ í¬ë¦¼', 'ë°”ë¥´ê³ ', 'í™”ì¥í•´ìš”!', 'ê·¸ë˜ë„', 'ì ë‹¹íˆ', 'ì´‰ì´‰í•˜ê³ ', 'ì¢‹ì•„ìš”', 'í™”ì¥', 'ì „', 'ê¸°ì´ˆë¥¼', 'ì—¬ëŸ¬ê°œ', 'í•´ì„œ', 'í”¼ë¶€', 'ë‹µë‹µí•œ', 'ê±°', 'ì‹«ì€ë°', 'ì´', 'ë¡œì…˜ì€', 'ì•ˆ', 'ê·¸ë˜ì„œ', 'ì¢‹ì•„ìš”', 'ì´ë¯¸', 'í•œ', 'í†µ', 'ë¹„ì›Œì„œ', 'í•œ', 'í†µ', 'ë”', 'ì‚´', 'ìƒê°ì…ë‹ˆë‹¤!']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer = tokenizer.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Korean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SYM'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „\n",
      "ê±´ì„±ì…ë‹ˆë‹¤ğŸ˜Š\n",
      "ì ë‹¹í•œ\n",
      "ìœ ë¶„ë„\n",
      "ê°€ì§€ê³ \n",
      "ìˆëŠ”ë°\n",
      "ê°€ë²¼ì›Œì„œ\n",
      "í™”ì¥\n",
      "ì „ì—\n",
      "ë°”ë¥´ê¸°ë„\n",
      "ì¢‹ì•„ìš”!\n",
      "ë°¤ì—\n",
      "ë°”ë¥´ë©´\n",
      "ì†ê¹Œì§€\n",
      "ìœ ìˆ˜ë¶„ê°ì´\n",
      "ì°¨ì˜¤ë¥´ê³ \n",
      "ì´‰ì´‰í•˜ê³ \n",
      "ì „\n",
      "ì•„ì£¼\n",
      "ì¢‹ì•„ìš”\n",
      "ì•…ê±´ì„±ì¸\n",
      "ë¶„ë“¤ì€\n",
      "í¬ë¦¼\n",
      "í•˜ë‚˜\n",
      "ë”\n",
      "ë°œë¼ì•¼\n",
      "í• \n",
      "ë“¯\n",
      "ì‹¶ì–´ìš”!\n",
      "ì „\n",
      "ì—„ì²­ë‚œ\n",
      "ê±´ì„±ì€\n",
      "ì•„ë‹ˆë¼ì„œ\n",
      "í”¼ê³¤í• \n",
      "ë•ŒëŠ”\n",
      "ê·¸ëƒ¥\n",
      "ë¡œì…˜ë§Œ\n",
      "ë°”ë¥´ê¸°ë„\n",
      "í•´ìš”!\n",
      "ì•„ì¹¨ì—ëŠ”\n",
      "ìŠ¤í‚¨\n",
      "ë°”ë¥´ê³ \n",
      "ë¡œì…˜ë§Œ\n",
      "ë°”ë¥´ê³ \n",
      "ì„ í¬ë¦¼\n",
      "ë°”ë¥´ê³ \n",
      "í™”ì¥í•´ìš”!\n",
      "ê·¸ë˜ë„\n",
      "ì ë‹¹íˆ\n",
      "ì´‰ì´‰í•˜ê³ \n",
      "ì¢‹ì•„ìš”\n",
      "í™”ì¥\n",
      "ì „\n",
      "ê¸°ì´ˆë¥¼\n",
      "ì—¬ëŸ¬ê°œ\n",
      "í•´ì„œ\n",
      "í”¼ë¶€\n",
      "ë‹µë‹µí•œ\n",
      "ê±°\n",
      "ì‹«ì€ë°\n",
      "ì´\n",
      "ë¡œì…˜ì€\n",
      "ì•ˆ\n",
      "ê·¸ë˜ì„œ\n",
      "ì¢‹ì•„ìš”\n",
      "ì´ë¯¸\n",
      "í•œ\n",
      "í†µ\n",
      "ë¹„ì›Œì„œ\n",
      "í•œ\n",
      "í†µ\n",
      "ë”\n",
      "ì‚´\n",
      "ìƒê°ì…ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì „',\n",
       " 'ê±´ì„±ì…ë‹ˆë‹¤ğŸ˜Š',\n",
       " 'ì ë‹¹í•œ',\n",
       " 'ìœ ë¶„ë„',\n",
       " 'ê°€ì§€ê³ ',\n",
       " 'ìˆëŠ”ë°',\n",
       " 'ê°€ë²¼ì›Œì„œ',\n",
       " 'í™”ì¥',\n",
       " 'ì „ì—',\n",
       " 'ë°”ë¥´ê¸°ë„',\n",
       " 'ì¢‹ì•„ìš”!',\n",
       " 'ë°¤ì—',\n",
       " 'ë°”ë¥´ë©´',\n",
       " 'ì†ê¹Œì§€',\n",
       " 'ìœ ìˆ˜ë¶„ê°ì´',\n",
       " 'ì°¨ì˜¤ë¥´ê³ ',\n",
       " 'ì´‰ì´‰í•˜ê³ ',\n",
       " 'ì „',\n",
       " 'ì•„ì£¼',\n",
       " 'ì¢‹ì•„ìš”',\n",
       " 'ì•…ê±´ì„±ì¸',\n",
       " 'ë¶„ë“¤ì€',\n",
       " 'í¬ë¦¼',\n",
       " 'í•˜ë‚˜',\n",
       " 'ë”',\n",
       " 'ë°œë¼ì•¼',\n",
       " 'í• ',\n",
       " 'ë“¯',\n",
       " 'ì‹¶ì–´ìš”!',\n",
       " 'ì „',\n",
       " 'ì—„ì²­ë‚œ',\n",
       " 'ê±´ì„±ì€',\n",
       " 'ì•„ë‹ˆë¼ì„œ',\n",
       " 'í”¼ê³¤í• ',\n",
       " 'ë•ŒëŠ”',\n",
       " 'ê·¸ëƒ¥',\n",
       " 'ë¡œì…˜ë§Œ',\n",
       " 'ë°”ë¥´ê¸°ë„',\n",
       " 'í•´ìš”!',\n",
       " 'ì•„ì¹¨ì—ëŠ”',\n",
       " 'ìŠ¤í‚¨',\n",
       " 'ë°”ë¥´ê³ ',\n",
       " 'ë¡œì…˜ë§Œ',\n",
       " 'ë°”ë¥´ê³ ',\n",
       " 'ì„ í¬ë¦¼',\n",
       " 'ë°”ë¥´ê³ ',\n",
       " 'í™”ì¥í•´ìš”!',\n",
       " 'ê·¸ë˜ë„',\n",
       " 'ì ë‹¹íˆ',\n",
       " 'ì´‰ì´‰í•˜ê³ ',\n",
       " 'ì¢‹ì•„ìš”',\n",
       " 'í™”ì¥',\n",
       " 'ì „',\n",
       " 'ê¸°ì´ˆë¥¼',\n",
       " 'ì—¬ëŸ¬ê°œ',\n",
       " 'í•´ì„œ',\n",
       " 'í”¼ë¶€',\n",
       " 'ë‹µë‹µí•œ',\n",
       " 'ê±°',\n",
       " 'ì‹«ì€ë°',\n",
       " 'ì´',\n",
       " 'ë¡œì…˜ì€',\n",
       " 'ì•ˆ',\n",
       " 'ê·¸ë˜ì„œ',\n",
       " 'ì¢‹ì•„ìš”',\n",
       " 'ì´ë¯¸',\n",
       " 'í•œ',\n",
       " 'í†µ',\n",
       " 'ë¹„ì›Œì„œ',\n",
       " 'í•œ',\n",
       " 'í†µ',\n",
       " 'ë”',\n",
       " 'ì‚´',\n",
       " 'ìƒê°ì…ë‹ˆë‹¤!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì„œ\n",
      "7\n",
      "ë¹„ì›Œì„œ\n",
      "ë§Œ\n",
      "ë¹ ë¥¸\n",
      "í•´ìš”\n",
      "ì•„ì¹¨\n",
      "í”¼ê³¤\n",
      "ë³´ì˜€\n",
      "ìƒê°\n",
      "í• \n",
      "ì„¸íŠ¸\n",
      "ì¸\n",
      "ë¶„ê°\n",
      "ìœ ìˆ˜\n",
      "í¼\n",
      "ì´ê±°\n",
      "ê°™\n",
      "ê±´ì„±\n",
      "ë„\n",
      "ìœ ë¶„\n",
      "í†µ\n",
      "ìŠµë‹ˆë‹¤\n",
      "ë°œë¼ì•¼\n",
      "ì€\n",
      "íŠ¸ëŸ¬ë¸”\n",
      "ì‚´\n",
      "ì ë‹¹íˆ\n",
      "ê³ \n",
      "í™”ì¥\n",
      "ë•Œë¬¸\n",
      "ì•„ì£¼\n",
      "ì–´ìš”\n",
      "ê·¸ë˜ë„\n",
      "ì…¨\n",
      "ë‹¤\n",
      "ì´ë¯¸\n",
      "ë°”ë¥´\n",
      "ë”\n",
      "í•œ\n",
      "ëŠ”\n",
      "ê½¤\n",
      "ì´ë‘\n",
      "ê°€ë²¼ì›Œì„œ\n",
      "ì¹˜ë£Œ\n",
      "ìˆ\n",
      "ì•„ìš”\n",
      "ì´ê±¸\n",
      "í•˜ë‚˜\n",
      "ì‹«\n",
      "ì—¬ëŸ¬\n",
      "!\n",
      "ë°\n",
      "ê·¸ë˜ì„œ\n",
      "ğŸ˜Š\n",
      "ê°€ì§€\n",
      "ì „\n",
      "ì…\n",
      "ë‹ˆë‹¹\n",
      "ê±°\n",
      "ì—„ì²­ë‚œ\n",
      "ê¹Œì§€\n",
      "ëŠ”ë°\n",
      "ì‚°\n",
      "ë‹µë‹µ\n",
      "ì¶”ì²œ\n",
      "ì—ì„œ\n",
      "ì†\n",
      "ì•…\n",
      "í•´\n",
      "ë˜\n",
      "ì œí’ˆ\n",
      "ë¡œì…˜\n",
      "ì„ í¬ë¦¼\n",
      "í”¼ë¶€ê³¼\n",
      "ì¢ìŒ€\n",
      "í•´ìš©\n",
      "í™”ë†ì„±\n",
      "ì‹¶\n",
      "ë¶„\n",
      "ì ë‹¹\n",
      "ë©´\n",
      "ì‚¬\n",
      "ì•ˆ\n",
      "ì£¼\n",
      "ê²Œ\n",
      "ê°”ì—ˆ\n",
      "ì—ˆ\n",
      "ë¡œ\n",
      "ì´‰ì´‰\n",
      "ë˜\n",
      "ë¥¼\n",
      "ê°œ\n",
      "ì‹œê°„\n",
      "ê¸°ì´ˆ\n",
      "í´ë Œì§•\n",
      "ê²ƒ\n",
      "ì—\n",
      "ì´ê²ƒì €ê²ƒ\n",
      "ë“¯\n",
      "í•´ì„œ\n",
      "ì´\n",
      "í¬ë¦¼\n",
      "ì€ë°\n",
      "ë“¤\n",
      "ì›\n",
      "ì‚°ëœ»\n",
      "í”¼ë¶€\n",
      "í•˜\n",
      "ë°¤\n",
      "ê·¸ëƒ¥\n",
      "ìŠ¤í‚¨\n",
      "ì°¨ì˜¤ë¥´\n",
      "ì •ë„\n",
      "ë•Œ\n",
      "ì¤„ì–´ë“œ\n",
      "ì…ë‹ˆë‹¤\n",
      "ê¸°\n",
      "ì•„ë‹ˆ\n",
      "ì¢‹\n"
     ]
    }
   ],
   "source": [
    "for v in nlp.vocab:\n",
    "    print(v.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-25 01:40:15,747\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-03-25 01:40:15,751\tINFO resource_spec.py:216 -- Starting Ray with 297.56 GiB memory available for workers and up to 195.31 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(num_cpus=64, object_store_memory = 200000 * 1024 * 1024, driver_object_store_memory = 100000 * 1024 * 1024)\n",
    "\n",
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/social_buzz_dataset/korean_dataset_tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   ['ê¹€ìŠ¬ê¸°ì´ì†Œë¯¸', 'ì™€', 'ì¢…ë‚˜ì´ë»']\n",
       "1                            ['ì•„ê¹Œ', 'í”¼ê³¤í• ë•Œ', 'ë‹¡', 'ëˆˆ', 'ì €ëŸ¼']\n",
       "2                        ['ì²˜ìŒ', 'ë´ë´', 'ê±', 'ë‹ˆì•¼', 'ëˆˆë¹›', 'ë„']\n",
       "3         ['ì´í¬ì¬', 'ì•„ë‹ˆ', 'í¬ì¬ì•¼', 'ì—ë°˜ë°', 'ë„ˆ', 'ã…‡ê±°', 'ì§„ì§œ', '...\n",
       "4                                          ['ì„±ë¯¼ì•„ì„¤ë¦¬', 'ì§€ë¦°ë‹¤']\n",
       "                                ...                        \n",
       "455055    ['êµ¬ì •', 'íŠ¹ê°€', 'ì—ìŠ¤í‹°ë¡œë”', 'ë¦¬ë°”ì´íƒˆë¼ì´ì§•', 'ìˆ˜í”„ë¦¼', 'ê¸€ë¡œ', ...\n",
       "455056    ['ì˜ì–´', 'ì•ˆì“°ê³ ', 'í•œêµ­', 'ì–´ë§Œ', 'ë“¤ì–´ê°„', 'ì˜ìƒ', 'ë„', 'ì°...\n",
       "455057    ['ì›ì¹™', 'ì¸ìŠ¤íƒ€', 'ê±°ë¥¸ë‹¤', 'ì–´í”Œ', 'ì•±', 'ë“±', 'ê±°ë¥¸ë‹¤', 'ìœ ...\n",
       "455058                                        ['ê°ì‚¬', 'í•©ë‹ˆë‹¤']\n",
       "455059                                       ['lets', 'go']\n",
       "Name: Comments_tokens, Length: 455060, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Comments_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Media Type</th>\n",
       "      <th>Site Name</th>\n",
       "      <th>Site Domain</th>\n",
       "      <th>Mention URL</th>\n",
       "      <th>Publisher Name</th>\n",
       "      <th>Publisher Username</th>\n",
       "      <th>Mention Title</th>\n",
       "      <th>...</th>\n",
       "      <th>Youtube Favorites</th>\n",
       "      <th>Synthesio Rank</th>\n",
       "      <th>User Age</th>\n",
       "      <th>User Gender</th>\n",
       "      <th>User Family Status</th>\n",
       "      <th>User Marital Status</th>\n",
       "      <th>User Affinities</th>\n",
       "      <th>User Jobs</th>\n",
       "      <th>User biography tags</th>\n",
       "      <th>Comments_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360101-91195377833</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>23:59:00 +0900 KST</td>\n",
       "      <td>Social network</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>http://www.facebook.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anonymous user</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ê¹€ìŠ¬ê¸°ì´ì†Œë¯¸', 'ì™€', 'ì¢…ë‚˜ì´ë»']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360101-91195377777</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>23:59:00 +0900 KST</td>\n",
       "      <td>Social network</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>http://www.facebook.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anonymous user</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ì•„ê¹Œ', 'í”¼ê³¤í• ë•Œ', 'ë‹¡', 'ëˆˆ', 'ì €ëŸ¼']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360101-91195377678</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>23:58:00 +0900 KST</td>\n",
       "      <td>Social network</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>http://www.facebook.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anonymous user</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ì²˜ìŒ', 'ë´ë´', 'ê±', 'ë‹ˆì•¼', 'ëˆˆë¹›', 'ë„']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360101-91195377621</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>23:58:00 +0900 KST</td>\n",
       "      <td>Social network</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>http://www.facebook.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anonymous user</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ì´í¬ì¬', 'ì•„ë‹ˆ', 'í¬ì¬ì•¼', 'ì—ë°˜ë°', 'ë„ˆ', 'ã…‡ê±°', 'ì§„ì§œ', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360101-91195377351</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>23:57:00 +0900 KST</td>\n",
       "      <td>Social network</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>http://www.facebook.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anonymous user</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ì„±ë¯¼ì•„ì„¤ë¦¬', 'ì§€ë¦°ë‹¤']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455055</th>\n",
       "      <td>360101-138651752690</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>00:21:00 +0900 KST</td>\n",
       "      <td>Forum</td>\n",
       "      <td>Cafe.Naver</td>\n",
       "      <td>http://cafe.naver.com</td>\n",
       "      <td>https://cafe.naver.com/ArticleRead.nhn?clubid=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ë‰´ì €ì§€ì½•ì½•] êµ¬ì •íŠ¹ê°€* ì—ìŠ¤í‹°ë¡œë” ë¦¬ë°”ì´íƒˆë¼ì´ì§• ìˆ˜í”„ë¦¼+ ê¸€ë¡œë²Œ ì•ˆí‹° ì—ì´ì§• íŒŒì›Œ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['êµ¬ì •', 'íŠ¹ê°€', 'ì—ìŠ¤í‹°ë¡œë”', 'ë¦¬ë°”ì´íƒˆë¼ì´ì§•', 'ìˆ˜í”„ë¦¼', 'ê¸€ë¡œ', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455056</th>\n",
       "      <td>360101-138585747518</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>00:04:00 +0900 KST</td>\n",
       "      <td>Video and Photo Sharing</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>http://www.youtube.com</td>\n",
       "      <td>https://www.youtube.com/watch?v=tv0xwv1vsfU&amp;lc...</td>\n",
       "      <td>ë¹ˆì€</td>\n",
       "      <td>UCklZYDy21MopvNiR4JvDAZA</td>\n",
       "      <td>Full Face in 10 Min âš¡ ASMR: CHANEL, Jeffree St...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ì˜ì–´', 'ì•ˆì“°ê³ ', 'í•œêµ­', 'ì–´ë§Œ', 'ë“¤ì–´ê°„', 'ì˜ìƒ', 'ë„', 'ì°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455057</th>\n",
       "      <td>360101-138569083547</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>00:04:00 +0900 KST</td>\n",
       "      <td>Forum</td>\n",
       "      <td>DC Inside</td>\n",
       "      <td>http://www.dcinside.com</td>\n",
       "      <td>https://gall.dcinside.com/board/view/?id=cosme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ê¸°ì´ˆ í™”ì¥í’ˆ ì¶”ì²œ</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ì›ì¹™', 'ì¸ìŠ¤íƒ€', 'ê±°ë¥¸ë‹¤', 'ì–´í”Œ', 'ì•±', 'ë“±', 'ê±°ë¥¸ë‹¤', 'ìœ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455058</th>\n",
       "      <td>360101-138601418195</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>00:02:00 +0900 KST</td>\n",
       "      <td>Forum</td>\n",
       "      <td>Cafe.Naver</td>\n",
       "      <td>http://cafe.naver.com</td>\n",
       "      <td>https://cafe.naver.com/ArticleRead.nhn?clubid=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ì´ì²œíŒ©í† ë¦¬] ì„¤í™”ìˆ˜ ììŒ2ì¢…ë°±í™”ì  ë¼ì¸ êµ¬í•˜ê¸°í˜ë“ ì œí’ˆ (ì„ ë¬¼ê°•ì¶”) 71000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ê°ì‚¬', 'í•©ë‹ˆë‹¤']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455059</th>\n",
       "      <td>360101-138585747588</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>00:01:00 +0900 KST</td>\n",
       "      <td>Video and Photo Sharing</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>http://www.youtube.com</td>\n",
       "      <td>https://www.youtube.com/watch?v=tv0xwv1vsfU&amp;lc...</td>\n",
       "      <td>Fayza Aurora</td>\n",
       "      <td>UCb9Q4Lff_2mJz20DQuEk78w</td>\n",
       "      <td>Full Face in 10 Min âš¡ ASMR: CHANEL, Jeffree St...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['lets', 'go']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455060 rows x 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Id        Date                Time  \\\n",
       "0        360101-91195377833  2017-12-30  23:59:00 +0900 KST   \n",
       "1        360101-91195377777  2017-12-30  23:59:00 +0900 KST   \n",
       "2        360101-91195377678  2017-12-30  23:58:00 +0900 KST   \n",
       "3        360101-91195377621  2017-12-30  23:58:00 +0900 KST   \n",
       "4        360101-91195377351  2017-12-30  23:57:00 +0900 KST   \n",
       "...                     ...         ...                 ...   \n",
       "455055  360101-138651752690  2020-01-24  00:21:00 +0900 KST   \n",
       "455056  360101-138585747518  2020-01-24  00:04:00 +0900 KST   \n",
       "455057  360101-138569083547  2020-01-24  00:04:00 +0900 KST   \n",
       "455058  360101-138601418195  2020-01-24  00:02:00 +0900 KST   \n",
       "455059  360101-138585747588  2020-01-24  00:01:00 +0900 KST   \n",
       "\n",
       "                     Media Type   Site Name              Site Domain  \\\n",
       "0                Social network    Facebook  http://www.facebook.com   \n",
       "1                Social network    Facebook  http://www.facebook.com   \n",
       "2                Social network    Facebook  http://www.facebook.com   \n",
       "3                Social network    Facebook  http://www.facebook.com   \n",
       "4                Social network    Facebook  http://www.facebook.com   \n",
       "...                         ...         ...                      ...   \n",
       "455055                    Forum  Cafe.Naver    http://cafe.naver.com   \n",
       "455056  Video and Photo Sharing     YouTube   http://www.youtube.com   \n",
       "455057                    Forum   DC Inside  http://www.dcinside.com   \n",
       "455058                    Forum  Cafe.Naver    http://cafe.naver.com   \n",
       "455059  Video and Photo Sharing     YouTube   http://www.youtube.com   \n",
       "\n",
       "                                              Mention URL  Publisher Name  \\\n",
       "0                                                     NaN  Anonymous user   \n",
       "1                                                     NaN  Anonymous user   \n",
       "2                                                     NaN  Anonymous user   \n",
       "3                                                     NaN  Anonymous user   \n",
       "4                                                     NaN  Anonymous user   \n",
       "...                                                   ...             ...   \n",
       "455055  https://cafe.naver.com/ArticleRead.nhn?clubid=...             NaN   \n",
       "455056  https://www.youtube.com/watch?v=tv0xwv1vsfU&lc...              ë¹ˆì€   \n",
       "455057  https://gall.dcinside.com/board/view/?id=cosme...             NaN   \n",
       "455058  https://cafe.naver.com/ArticleRead.nhn?clubid=...             NaN   \n",
       "455059  https://www.youtube.com/watch?v=tv0xwv1vsfU&lc...    Fayza Aurora   \n",
       "\n",
       "              Publisher Username  \\\n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "455055                       NaN   \n",
       "455056  UCklZYDy21MopvNiR4JvDAZA   \n",
       "455057                       NaN   \n",
       "455058                       NaN   \n",
       "455059  UCb9Q4Lff_2mJz20DQuEk78w   \n",
       "\n",
       "                                            Mention Title  ...  \\\n",
       "0                                  Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”  ...   \n",
       "1                                  Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”  ...   \n",
       "2                                  Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”  ...   \n",
       "3                                  Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”  ...   \n",
       "4                                  Estee Lauder KR ì—ìŠ¤í‹° ë¡œë”  ...   \n",
       "...                                                   ...  ...   \n",
       "455055  [ë‰´ì €ì§€ì½•ì½•] êµ¬ì •íŠ¹ê°€* ì—ìŠ¤í‹°ë¡œë” ë¦¬ë°”ì´íƒˆë¼ì´ì§• ìˆ˜í”„ë¦¼+ ê¸€ë¡œë²Œ ì•ˆí‹° ì—ì´ì§• íŒŒì›Œ...  ...   \n",
       "455056  Full Face in 10 Min âš¡ ASMR: CHANEL, Jeffree St...  ...   \n",
       "455057                                          ê¸°ì´ˆ í™”ì¥í’ˆ ì¶”ì²œ  ...   \n",
       "455058        [ì´ì²œíŒ©í† ë¦¬] ì„¤í™”ìˆ˜ ììŒ2ì¢…ë°±í™”ì  ë¼ì¸ êµ¬í•˜ê¸°í˜ë“ ì œí’ˆ (ì„ ë¬¼ê°•ì¶”) 71000  ...   \n",
       "455059  Full Face in 10 Min âš¡ ASMR: CHANEL, Jeffree St...  ...   \n",
       "\n",
       "       Youtube Favorites  Synthesio Rank  User Age  User Gender  \\\n",
       "0                    NaN             1.6       NaN          NaN   \n",
       "1                    NaN             1.6       NaN          NaN   \n",
       "2                    NaN             1.6       NaN          NaN   \n",
       "3                    NaN             1.6       NaN          NaN   \n",
       "4                    NaN             1.6       NaN          NaN   \n",
       "...                  ...             ...       ...          ...   \n",
       "455055               NaN             5.0       NaN          NaN   \n",
       "455056               NaN             5.0       NaN          NaN   \n",
       "455057               NaN             5.0       NaN          NaN   \n",
       "455058               NaN             5.0       NaN          NaN   \n",
       "455059               NaN             5.0       NaN          NaN   \n",
       "\n",
       "        User Family Status  User Marital Status  User Affinities  User Jobs  \\\n",
       "0                      NaN                  NaN              NaN        NaN   \n",
       "1                      NaN                  NaN              NaN        NaN   \n",
       "2                      NaN                  NaN              NaN        NaN   \n",
       "3                      NaN                  NaN              NaN        NaN   \n",
       "4                      NaN                  NaN              NaN        NaN   \n",
       "...                    ...                  ...              ...        ...   \n",
       "455055                 NaN                  NaN              NaN        NaN   \n",
       "455056                 NaN                  NaN              NaN        NaN   \n",
       "455057                 NaN                  NaN              NaN        NaN   \n",
       "455058                 NaN                  NaN              NaN        NaN   \n",
       "455059                 NaN                  NaN              NaN        NaN   \n",
       "\n",
       "        User biography tags                                    Comments_tokens  \n",
       "0                       NaN                            ['ê¹€ìŠ¬ê¸°ì´ì†Œë¯¸', 'ì™€', 'ì¢…ë‚˜ì´ë»']  \n",
       "1                       NaN                     ['ì•„ê¹Œ', 'í”¼ê³¤í• ë•Œ', 'ë‹¡', 'ëˆˆ', 'ì €ëŸ¼']  \n",
       "2                       NaN                 ['ì²˜ìŒ', 'ë´ë´', 'ê±', 'ë‹ˆì•¼', 'ëˆˆë¹›', 'ë„']  \n",
       "3                       NaN  ['ì´í¬ì¬', 'ì•„ë‹ˆ', 'í¬ì¬ì•¼', 'ì—ë°˜ë°', 'ë„ˆ', 'ã…‡ê±°', 'ì§„ì§œ', '...  \n",
       "4                       NaN                                   ['ì„±ë¯¼ì•„ì„¤ë¦¬', 'ì§€ë¦°ë‹¤']  \n",
       "...                     ...                                                ...  \n",
       "455055                  NaN  ['êµ¬ì •', 'íŠ¹ê°€', 'ì—ìŠ¤í‹°ë¡œë”', 'ë¦¬ë°”ì´íƒˆë¼ì´ì§•', 'ìˆ˜í”„ë¦¼', 'ê¸€ë¡œ', ...  \n",
       "455056                  NaN  ['ì˜ì–´', 'ì•ˆì“°ê³ ', 'í•œêµ­', 'ì–´ë§Œ', 'ë“¤ì–´ê°„', 'ì˜ìƒ', 'ë„', 'ì°...  \n",
       "455057                  NaN  ['ì›ì¹™', 'ì¸ìŠ¤íƒ€', 'ê±°ë¥¸ë‹¤', 'ì–´í”Œ', 'ì•±', 'ë“±', 'ê±°ë¥¸ë‹¤', 'ìœ ...  \n",
       "455058                  NaN                                      ['ê°ì‚¬', 'í•©ë‹ˆë‹¤']  \n",
       "455059                  NaN                                     ['lets', 'go']  \n",
       "\n",
       "[455060 rows x 52 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id, comment_text...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lexeme == tokenizer...\n",
    "- keyword == whitespace ë‹¨ìœ„ + ì“¸ë° ì—†ëŠ” í† í° ì œê±°..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.zh import Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chinese(use_jieba = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Jieba not installed. Either set Chinese.use_jieba = False, or install it https://github.com/fxsjy/jieba",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/lang/zh/__init__.py\u001b[0m in \u001b[0;36mtry_jieba_import\u001b[0;34m(use_jieba)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mjieba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jieba'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-f317f9299d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChinese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_jieba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"è˜‹æœå…¬å¸æ­£è€ƒé‡ç”¨ä¸€å„„å…ƒè²·ä¸‹è‹±åœ‹çš„æ–°å‰µå…¬å¸\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, make_doc, max_length, meta, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mmake_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/lang/zh/__init__.py\u001b[0m in \u001b[0;36mcreate_tokenizer\u001b[0;34m(cls, nlp)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mChineseTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/lang/zh/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cls, nlp)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_jieba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_jieba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjieba_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_jieba_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_jieba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/lang/zh/__init__.py\u001b[0m in \u001b[0;36mtry_jieba_import\u001b[0;34m(use_jieba)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;34m\"or install it https://github.com/fxsjy/jieba\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             )\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Jieba not installed. Either set Chinese.use_jieba = False, or install it https://github.com/fxsjy/jieba"
     ]
    }
   ],
   "source": [
    "nlp = \n",
    "doc2 = nlp(u\"è˜‹æœå…¬å¸æ­£è€ƒé‡ç”¨ä¸€å„„å…ƒè²·ä¸‹è‹±åœ‹çš„æ–°å‰µå…¬å¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.language.Language.<lambda>(nlp)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chinese.factories['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function <lambda> in module spacy.language:\n",
      "\n",
      "<lambda> lambda nlp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Chinese)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
